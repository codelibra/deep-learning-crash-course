{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_Script_prisma.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ATzLsfwhn7x3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "2e12a722-c5ae-4dcc-b81d-e69f38ff62d6"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "! pip install dropbox\n",
        "from dropbox import Dropbox\n",
        "import time\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.keras import backend\n",
        "from tensorflow.contrib.keras import models\n",
        "from tensorflow.contrib.keras import applications\n",
        "\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "from scipy.misc import imsave\n",
        "\n",
        "\n",
        "# style_map\n",
        "style_map={}\n",
        "style_map.update({'Painting':'painting.jpg'})\n",
        "style_map.update({'Wave':'wave.png'})\n",
        "style_map.update({'Modern Art':'modern_Art.jpg'})\n",
        "\n",
        "# constants\n",
        "height = 512\n",
        "width = 512\n",
        "\n",
        "# Helper functions and classes\n",
        "def content_loss(content, combination):\n",
        "\treturn backend.sum(backend.square(combination - content))\n",
        "\n",
        "\n",
        "def gram_matrix(x):\n",
        "    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = backend.dot(features, backend.transpose(features))\n",
        "    return gram\n",
        "\n",
        "\n",
        "def style_loss(style, combination):\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = height * width\n",
        "    return backend.sum(backend.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
        "\n",
        "\n",
        "def total_variation_loss(x):\n",
        "    a = backend.square(x[:, :height-1, :width-1, :] - x[:, 1:, :width-1, :])\n",
        "    b = backend.square(x[:, :height-1, :width-1, :] - x[:, :height-1, 1:, :])\n",
        "    return backend.sum(backend.pow(a + b, 1.25))\n",
        "\n",
        "\n",
        "def eval_loss_and_grads(f_outputs, x):\n",
        "    x = x.reshape((1, height, width, 3))\n",
        "    outs = f_outputs([x])\n",
        "    loss_value = outs[0]\n",
        "    grad_values = outs[1].flatten().astype('float64')\n",
        "    return loss_value, grad_values\n",
        "\n",
        "def neural_style_script(content_image, style_image):\n",
        "  content_image = Image.open(content_image)\n",
        "  content_image = content_image.resize((width, height))\n",
        "  style_image = style_map.get(style_image)\n",
        "  style_image = Image.open(style_image)\n",
        "  style_image = style_image.resize((width, height))\n",
        "  content_array = np.asarray(content_image, dtype='float32')\n",
        "  content_array = np.expand_dims(content_array, axis=0)\n",
        "  style_array = np.asarray(style_image, dtype='float32')\n",
        "  style_array = np.expand_dims(style_array, axis=0)\n",
        "  content_array[:, :, :, 0] -= 103.939\n",
        "  content_array[:, :, :, 1] -= 116.779\n",
        "  content_array[:, :, :, 2] -= 123.68\n",
        "  content_array = content_array[:, :, :, ::-1]\n",
        "  style_array[:, :, :, 0] -= 103.939\n",
        "  style_array[:, :, :, 1] -= 116.779\n",
        "  style_array[:, :, :, 2] -= 123.68\n",
        "  style_array = style_array[:, :, :, ::-1]\n",
        "  content_image = backend.variable(content_array)\n",
        "  style_image = backend.variable(style_array)\n",
        "  combination_image = backend.placeholder((1, height, width, 3))\n",
        "  input_tensor = backend.concatenate([content_image,\n",
        "    style_image,\n",
        "    combination_image], axis=0)\n",
        "  model = applications.VGG16(input_tensor=input_tensor, weights='imagenet',include_top=False)  \n",
        "  content_weight = 0.025\n",
        "  style_weight = 5.0\n",
        "  total_variation_weight = 1.0\n",
        "  loss = backend.variable(0.)\n",
        "  layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "  layer_features = layers['block2_conv2']\n",
        "  content_image_features = layer_features[0, :, :, :]\n",
        "  combination_features = layer_features[2, :, :, :]\n",
        "  loss = loss + content_weight * content_loss(content_image_features, combination_features)\n",
        "  feature_layers = ['block1_conv2', 'block2_conv2',\n",
        "  'block3_conv3', 'block4_conv3',\n",
        "  'block5_conv3']\n",
        "  for layer_name in feature_layers:\n",
        "    layer_features = layers[layer_name]\n",
        "    style_features = layer_features[1, :, :, :]\n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    sl = style_loss(style_features, combination_features)\n",
        "    loss += (style_weight / len(feature_layers)) * sl\n",
        "\n",
        "  loss += total_variation_weight * total_variation_loss(combination_image)\n",
        "  grads = backend.gradients(loss, combination_image)\n",
        "  outputs = [loss]\n",
        "  outputs += grads\n",
        "  f_outputs = backend.function([combination_image], outputs)\n",
        "  evaluator = Evaluator(f_outputs)\n",
        "  x = np.random.uniform(0, 255, (1, height, width, 3)) - 128.\n",
        "  iterations = 1\n",
        "  for i in range(iterations):\n",
        "     print('Start of iteration', i)\n",
        "     start_time = time.time()\n",
        "     x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
        "       fprime=evaluator.grads, maxfun=20)\n",
        "     print('Current loss value:', min_val)\n",
        "     end_time = time.time()\n",
        "     print('Iteration %d completed in %ds' % (i, end_time - start_time))\n",
        "  x = x.reshape((height, width, 3))\n",
        "  x = x[:, :, ::-1]\n",
        "  x[:, :, 0] += 103.939\n",
        "  x[:, :, 1] += 116.779\n",
        "  x[:, :, 2] += 123.68\n",
        "  x = np.clip(x, 0, 255).astype('uint8')\n",
        "  Image.fromarray(x).save(file)\n",
        "\n",
        "\n",
        "class Evaluator(object):\n",
        "    def __init__(self, f_outputs):\n",
        "        self.loss_value = None\n",
        "        self.grads_values = None\n",
        "        self.f_outputs = f_outputs\n",
        "\n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        loss_value, grad_values = eval_loss_and_grads(self.f_outputs, x)\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "\n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values    \n",
        "\n",
        "\n",
        "while(True):\n",
        "  #API Token\n",
        "  dbx = Dropbox('56Avmht1CGkAAAAAAAABS8gYYmjrmVC5HZc6ThJbMT168Y1MrWhY0wjfXUln64i4')\n",
        "\n",
        "\n",
        "  # Iterate over styles folder and download on colab\n",
        "  for entry in dbx.files_list_folder('/prisma/styles/').entries:\n",
        "    dbx.files_download_to_file(\"./\"+entry.name, '/prisma/styles/'+entry.name)\n",
        "\n",
        "  # Iterate over output subfolders\n",
        "  out_sub_folders=[]\n",
        "  for entry in dbx.files_list_folder('/prisma/output/').entries:\n",
        "    out_sub_folders.insert(1,entry.name)\n",
        "\n",
        "  # Iterate over files in each output subfolder and add it to a set \n",
        "  out_files = set()\n",
        "  for folder in out_sub_folders:  \n",
        "    for entry in dbx.files_list_folder('/prisma/output/'+folder).entries:\n",
        "      out_files.add(folder+\"/\"+entry.name)\n",
        "  \n",
        "  in_sub_folders=[]\n",
        "  to_process_images=[]\n",
        "\n",
        "  # Iterate over input subfolders \n",
        "  for entry in dbx.files_list_folder('/prisma/input/').entries:\n",
        "    in_sub_folders.insert(1, entry.name)\n",
        "\n",
        "  # Iterate over each file in input subfolders and check whether in output folder\n",
        "  # if not add it in to_process_images\n",
        "  for folder in in_sub_folders:  \n",
        "    for entry in dbx.files_list_folder('/prisma/input/'+folder).entries:\n",
        "      if folder+\"/\"+entry.name not in out_files:\n",
        "        to_process_images.insert(1,\"/prisma/input/\"+folder+\"/\"+entry.name)\n",
        "\n",
        "  # download from dropbox, files toprocess\n",
        "  # extract the filename to refer further\n",
        "  filenames_toproc =[]\n",
        "  for file in to_process_images:\n",
        "    tokens= file.split('/')\n",
        "    filenames_toproc.insert(1,tokens[len(tokens)-1]+\"/\"+tokens[len(tokens)-2])\n",
        "    dbx.files_download_to_file(\"./\"+tokens[len(tokens)-1], file)\n",
        "\n",
        "  for file in filenames_toproc:\n",
        "    print(\"1---->\",file)\n",
        "    neural_style_script(file.split(\"/\")[0], file.split(\"_\")[0])\n",
        "    with open(file.split(\"/\")[0], \"rb\") as imageFile:\n",
        "        output = imageFile.read()\n",
        "    dbx.files_upload(output,'/prisma/output/'+file.split(\"/\")[1]+'/'+file.split(\"/\")[0])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dropbox in /usr/local/lib/python3.6/dist-packages (8.8.1)\r\n",
            "Requirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from dropbox) (1.11.0)\r\n",
            "Requirement already satisfied: requests>=2.16.2 in /usr/local/lib/python3.6/dist-packages (from dropbox) (2.18.4)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.16.2->dropbox) (2018.4.16)\r\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.16.2->dropbox) (3.0.4)\r\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.16.2->dropbox) (2.6)\r\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.16.2->dropbox) (1.22)\r\n",
            "1----> Wave_ak.jpg/ak5146@nyu.edu\n",
            "Start of iteration 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CKPPFB10zDLu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}